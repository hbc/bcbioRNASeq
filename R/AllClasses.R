# TODO Inform the user about loading counts at gene or transcript level
# TODO Reduce the message spam about project-summary.yaml in the load call
# TODO Inform the user that we're using featureCounts for STAR, HISAT2



# Class Definitions ============================================================
#' @rdname bcbioRNASeq
#' @aliases NULL
#' @exportClass bcbioRNASeq
#' @usage NULL
bcbioRNASeq <- setClass(
    Class = "bcbioRNASeq",
    contains = "RangedSummarizedExperiment"
)

setClassUnion("missingOrNULL", c("missing", "NULL"))



# Internal Functions ===========================================================
# Used for bcbio pipeline checks
.dataHasVariation <- function(dds) {
    !all(rowSums(assay(dds) == assay(dds)[, 1L]) == ncol(dds))
}



# Constructors =================================================================
#' `bcbioRNASeq` Object and Constructor
#'
#' `bcbioRNASeq` is an S4 class that extends `RangedSummarizedExperiment`, and
#' is designed to store a [bcbio](https://bcbio-nextgen.readthedocs.org) RNA-seq
#' analysis.
#'
#' Simply point to the final upload directory generated by
#' [bcbio](https://bcbio-nextgen.readthedocs.io/), and this constructor function
#' will take care of the rest. It automatically imports RNA-seq counts,
#' metadata, and the program versions used.
#'
#' This class contains raw read counts and length-scaled
#' transcripts per million (TPM) generated by [tximport::tximport()]. Counts can
#' be loaded at gene or transcript level.
#'
#' @section Genome build:
#'
#' Ensure that the organism and genome build used with bcio match correctly
#' here in the function call. In particular, for the legacy *Homo sapiens*
#' GRCh37/hg19 genome build, ensure that `genomeBuild = "GRCh37"`. Otherwise,
#' the genomic ranges set in `rowRanges()` will mismatch. It is recommended
#' for current projects that GRCh38/hg38 is used in place of GRCh37/hg19
#' if possible.
#'
#' @section Metadata:
#'
#' The [metadata()] accessor contains:
#'
#' - Sample quality control metrics.
#' - Ensembl annotations.
#' - Server run paths.
#' - R session information (e.g. [utils::sessionInfo()]).
#'
#' @section DESeq2:
#'
#' DESeq2 is run automatically when [bcbioRNASeq()] is called, and variance
#' stabilized counts are slotted into [assays()]. If the number of samples is
#' bigger than the `transformationLimit` argument, `rlog` and `vst` counts will
#' not be slotted into `assays()`. In this case, we recommend visualization
#' using [tmm()] counts, which are automatically calculated using edgeR.
#'
#' @section Remote data:
#'
#' When working in RStudio, we recommend connecting to the bcbio run directory
#' as a remote connection over
#' [sshfs](https://github.com/osxfuse/osxfuse/wiki/SSHFS).
#'
#' @note `bcbioRNASeq` extended `SummarizedExperiment` prior to v0.2.0, where we
#'   migrated to `RangedSummarizedExperiment`.
#'
#' @rdname bcbioRNASeq
#' @aliases bcbioRNASeq-class
#' @docType class
#' @family S4 Object
#' @author Michael Steinbaugh, Lorena Pantano, Rory Kirchner, Victor Barrera
#'
#' @inheritParams bcbioBase::prepareSummarizedExperiment
#' @inheritParams general
#' @param uploadDir `string`. Path to final upload directory. This path is set
#'   when running "`bcbio_nextgen -w template`".
#' @param level `string`. Import counts at gene level ("`genes`"; *default*) or
#'   transcript level ("`transcripts`"; *advanced use*).
#' @param caller `string`. Expression caller:
#'   - "`salmon`" (*default*): [Salmon](https://combine-lab.github.io/salmon)
#'     alignment-free, quasi-mapped counts.
#'   - "`kallisto`". [Kallisto](https://pachterlab.github.io/kallisto)
#'     alignment-free, pseudo-aligned counts.
#'   - "`sailfish`". [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish)
#'     alignment-free, lightweight counts.
#'   - "`star`": [STAR](https://github.com/alexdobin/STAR)
#'     (Spliced Transcripts Alignment to a Reference) aligned counts.
#'   - "`hisat2`": [HISAT2](https://ccb.jhu.edu/software/hisat2)
#'     (Hierarchical Indexing for Spliced Alignment of Transcripts) graph-based
#'     aligned counts.
#' @param samples `character` or `NULL`. *Optional.* Specify a subset of samples
#'   to load. The names must match the `description` specified in the bcbio YAML
#'   metadata. If a `sampleMetadataFile` is provided, that will take priority
#'   for sample selection. Typically this can be left unset.
#' @param censorSamples `character` or `NULL`. *Optional.* Samples to exclude
#'   from the analysis.
#' @param sampleMetadataFile `string` or `NULL`. *Optional.* Custom metadata
#'   file containing sample information. Otherwise defaults to sample metadata
#'   saved in the YAML file. Remote URLs are supported. Typically this can be
#'   left unset.
#' @param organism `string` or `NULL`. Organism name. Use the full Latin name
#'   (e.g. "Homo sapiens"), since this will be input downstream to AnnotationHub
#'   and ensembldb, unless `gffFile` is set. If left `NULL` (*not recommended*),
#'   the function call will skip loading gene/transcript-level annotations into
#'   [rowRanges()]. This can be useful for poorly annotation genomes or
#'   experiments involving multiple genomes.
#' @param genomeBuild `string` or `NULL`. *Optional.* Ensembl genome build name
#'   (e.g. "GRCh38"). This will be passed to AnnotationHub for `EnsDb`
#'   annotation matching, unless `gffFile` is set.
#' @param ensemblRelease *Optional.* Ensembl release version. If unset,
#'   defaults to current release, and does not typically need to be
#'   user-defined. Passed to AnnotationHub for `EnsDb` annotation matching,
#'   unless `gffFile` is set.
#' @param gffFile `string` or `NULL`. *Advanced use; not recommended.* By
#'   default, we recommend leaving this `NULL` for genomes that are supported on
#'   Ensembl. In this case, the row annotations ([rowRanges()]) will be obtained
#'   automatically from Ensembl by passing the `organism`, `genomeBuild`, and
#'   `ensemblRelease` arguments to AnnotationHub and ensembldb. For a genome
#'   that is not supported on Ensembl and/or AnnotationHub, a GFF/GTF (General
#'   Feature Format) file is required. Generally, we recommend using a GTF
#'   (GFFv2) file here over a GFF3 file if possible, although all GFF formats
#'   are supported. The function will internally generate a `TxDb` containing
#'   transcript-to-gene mappings and construct a `GRanges` object containing the
#'   genomic ranges ([rowRanges()]).
#' @param vst `boolean`. Calculate variance-stabilizing transformation using
#'   [DESeq2::varianceStabilizingTransformation()]. Recommended by default
#'   for visualization.
#' @param rlog `boolean`. Calcualte regularized log transformation using
#'   [DESeq2::rlog()]. This calculation is slow for large datasets and now
#'   discouraged by default for visualization.
#' @param ... Additional arguments, slotted into the [metadata()] accessor.
#'
#' @return `bcbioRNASeq`.
#' @export
#'
#' @seealso
#' - [SummarizedExperiment::SummarizedExperiment()].
#' - [methods::initialize()].
#' - [methods::validObject()].
#' - [BiocGenerics::updateObject()].
#' - `.S4methods(class = "bcbioRNASeq")`.
#'
#' @examples
#' upload_dir <- system.file("extdata/bcbio", package = "bcbioRNASeq")
#'
#' # Gene level
#' x <- bcbioRNASeq(
#'     uploadDir = upload_dir,
#'     level = "genes",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(x)
#' is(x, "RangedSummarizedExperiment")
#' validObject(x)
#'
#' # Transcript level
#' x <- bcbioRNASeq(
#'     uploadDir = upload_dir,
#'     level = "transcripts",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(x)
#' validObject(x)
bcbioRNASeq <- function(
    uploadDir,
    level = c("genes", "transcripts"),
    caller = c("salmon", "kallisto", "sailfish", "star", "hisat2"),
    interestingGroups = "sampleName",
    samples = NULL,
    censorSamples = NULL,
    sampleMetadataFile = NULL,
    organism = NULL,
    genomeBuild = NULL,
    ensemblRelease = NULL,
    gffFile = NULL,
    transgeneNames = NULL,
    spikeNames = NULL,
    vst = TRUE,
    rlog = FALSE,
    ...
) {
    dots <- list(...)

    # Legacy arguments =========================================================
    # nocov start
    call <- match.call(expand.dots = TRUE)
    # annotable
    if ("annotable" %in% names(call)) {
        stop("`annotable` is defunct. Consider using `gffFile` instead.")
    }
    # ensemblVersion
    if ("ensemblVersion" %in% names(call)) {
        warning("Use `ensemblRelease` instead of `ensemblVersion`")
        ensemblRelease <- call[["ensemblVersion"]]
        dots[["ensemblVersion"]] <- NULL
    }
    # organism
    if (!"organism" %in% names(call)) {
        warning(paste(
            "`organism` is recommended for defining",
            "annotations in `rowRanges()`"
        ))
    }
    # transformationLimit
    if ("transformationLimit" %in% names(call)) {
        stop(paste(
            "`transformationLimit` is deprecated in favor of",
            "separate `vst` and `rlog` arguments"
        ))
    }
    dots <- Filter(Negate(is.null), dots)
    # nocov end

    # Assert checks ============================================================
    assert_is_a_string(uploadDir)
    assert_all_are_dirs(uploadDir)
    level <- match.arg(level)
    caller <- match.arg(caller)
    if (level == "transcripts") {
        assert_is_subset(caller, c("salmon", "kallisto", "sailfish"))
    }
    assertIsAStringOrNULL(sampleMetadataFile)
    assert_is_any_of(samples, c("character", "NULL"))
    assert_is_any_of(censorSamples, c("character", "NULL"))
    assert_is_character(interestingGroups)
    assertIsAStringOrNULL(organism)
    assertIsAnImplicitIntegerOrNULL(ensemblRelease)
    assertIsAStringOrNULL(genomeBuild)
    assert_is_any_of(transgeneNames, c("character", "NULL"))
    assert_is_any_of(spikeNames, c("character", "NULL"))
    assertIsAStringOrNULL(gffFile)
    if (is_a_string(gffFile)) {
        assert_all_are_existing_files(gffFile)
    }
    assert_is_a_bool(vst)
    assert_is_a_bool(rlog)

    # Directory paths ==========================================================
    uploadDir <- normalizePath(uploadDir, winslash = "/", mustWork = TRUE)
    projectDir <- list.files(
        path = uploadDir,
        pattern = bcbioBase::projectDirPattern,
        full.names = FALSE,
        recursive = FALSE
    )
    assert_is_a_string(projectDir)
    message(projectDir)
    match <- str_match(projectDir, bcbioBase::projectDirPattern)
    runDate <- as.Date(match[[2L]])
    template <- match[[3L]]
    projectDir <- file.path(uploadDir, projectDir)
    assert_all_are_dirs(projectDir)
    sampleDirs <- sampleDirs(uploadDir)
    assert_all_are_dirs(sampleDirs)

    # Project summary YAML =====================================================
    yamlFile <- file.path(projectDir, "project-summary.yaml")
    assert_all_are_existing_files(yamlFile)
    yaml <- readYAML(yamlFile)

    # bcbio run information ====================================================
    dataVersions <- readDataVersions(
        file = file.path(projectDir, "data_versions.csv")
    )
    assert_is_tbl_df(dataVersions)

    programVersions <- readProgramVersions(
        file = file.path(projectDir, "programs.txt")
    )
    assert_is_tbl_df(programVersions)

    bcbioLog <- readLog(
        file = file.path(projectDir, "bcbio-nextgen.log")
    )
    assert_is_character(bcbioLog)

    bcbioCommandsLog <- readLog(
        file = file.path(projectDir, "bcbio-nextgen-commands.log")
    )
    assert_is_character(bcbioCommandsLog)

    # Sequencing lanes =========================================================
    if (any(grepl(x = sampleDirs, pattern = bcbioBase::lanePattern))) {
        # nocov start
        lanes <- str_match(names(sampleDirs), bcbioBase::lanePattern) %>%
            .[, 2L] %>%
            unique() %>%
            length()
        message(paste(
            lanes, "sequencing lane detected", "(technical replicates)"
        ))
        # nocov end
    } else {
        lanes <- 1L
    }
    assert_is_an_integer(lanes)

    # Column data ==============================================================
    colData <- readYAMLSampleData(yamlFile)

    # Subset the samples
    if (is_a_string(sampleMetadataFile)) {
        # Replace columns with external, user-defined metadata, if desired. This
        # is nice for correcting metadata issues that aren't easy to fix by
        # editing the bcbio YAML output.
        userColData <- readSampleData(sampleMetadataFile, lanes = lanes)
        # Drop columns that are defined from the auto metadata
        setdiff <- setdiff(colnames(colData), colnames(userColData))
        # Note that we're allowing the user to subset the samples by the
        # metadata input here
        colData <- colData[rownames(userColData), setdiff, drop = FALSE]
        colData <- cbind(userColData, colData)
    } else if (is.character(samples)) {
        assert_is_subset(samples, colData[["description"]])
        colData <- colData %>%
            .[.[["description"]] %in% samples, , drop = FALSE]
    } else if (is.character(censorSamples)) {
        colData <- colData %>%
            .[!.[["description"]] %in% censorSamples, , drop = FALSE]
    }

    # Sanitize into factors
    colData <- sanitizeSampleData(colData)

    # Sample metrics. Note that sample metrics used for QC plots are not
    # currently generated when using fast RNA-seq workflow. This depends upon
    # MultiQC and aligned counts generated with STAR.
    message("Reading sample metrics")
    metrics <- readYAMLSampleMetrics(yamlFile)
    if (length(metrics)) {
        assert_is_data.frame(metrics)
        assert_are_disjoint_sets(colnames(colData), colnames(metrics))
        colData <- cbind(colData, metrics)
    } else {
        message("Fast mode detected. No metrics were calculated.")
    }

    # Subset sample directories by metadata ====================================
    samples <- rownames(colData)
    assert_is_subset(samples, names(sampleDirs))
    if (length(samples) < length(sampleDirs)) {
        message(paste(
            "Loading a subset of samples:",
            str_trunc(toString(samples), width = 80L),
            sep = "\n"
        ))
        allSamples <- FALSE
        sampleDirs <- sampleDirs[samples]
    } else {
        allSamples <- TRUE
    }

    # Interesting groups =======================================================
    interestingGroups <- camel(interestingGroups)
    assert_is_subset(interestingGroups, colnames(colData))

    # Transcript-to-gene mappings ==============================================
    tx2geneFile <- file.path(projectDir, "tx2gene.csv")
    assert_all_are_existing_files(tx2geneFile)
    tx2gene <- readTx2gene(tx2geneFile)

    # Read counts ==============================================================
    # Use tximport by default for transcript-aware callers.
    # Otherwise, resort to loading the featureCounts aligned counts data.
    if (caller %in% c("salmon", "kallisto", "sailfish")) {
        # tximport
        if (level == "transcripts") {
            txOut <- TRUE
        } else {
            txOut <- FALSE
        }
        txi <- .tximport(
            sampleDirs = sampleDirs,
            type = caller,
            txIn = TRUE,
            txOut = txOut,
            tx2gene = tx2gene
        )
        # TPM/abundance: transcripts per million
        tpm <- txi[["abundance"]]
        assert_is_matrix(tpm)
        # counts: raw counts
        counts <- txi[["counts"]]
        assert_is_matrix(counts)
        # length: average transcript length
        length <- txi[["length"]]
        assert_is_matrix(length)
        # countsFromAbundance: character describing TPM
        countsFromAbundance <- txi[["countsFromAbundance"]]
        assert_is_character(countsFromAbundance)
    } else if (caller %in% c("star", "hisat2")) {
        tpm <- NULL
        length <- NULL
        countsFromAbundance <- NULL
        # Load up the featureCounts aligned counts matrix
        counts <- readFileByExtension(file.path(projectDir, "combined.counts"))
        assert_is_matrix(counts)
        colnames(counts) <- makeNames(colnames(counts))
        # Subset the combined matrix to match the samples
        assert_is_subset(names(sampleDirs), colnames(counts))
        counts <- counts[, names(sampleDirs), drop = FALSE]
    }

    # Ensure `colData` matches the colnames in `assays()`
    colData <- colData[colnames(counts), , drop = FALSE]

    # Row data =================================================================
    rowRangesMetadata <- NULL
    if (is_a_string(gffFile)) {
        rowRanges <- makeGRangesFromGFF(gffFile)
    } else if (is_a_string(organism)) {
        # ah: AnnotationHub
        ah <- makeGRangesFromEnsembl(
            organism = organism,
            format = level,
            genomeBuild = genomeBuild,
            release = ensemblRelease,
            metadata = TRUE
        )
        assert_is_list(ah)
        assert_are_identical(names(ah), c("data", "metadata"))
        rowRanges <- ah[["data"]]
        assert_is_all_of(rowRanges, "GRanges")
        rowRangesMetadata <- ah[["metadata"]]
        assert_is_data.frame(rowRangesMetadata)
        genomeBuild <- rowRangesMetadata %>%
            filter(!!sym("name") == "genome_build") %>%
            pull("value")
        assert_is_a_string(genomeBuild)
    } else {
        rowRanges <- emptyRanges(rownames(counts))
    }

    # Gene-level variance stabilization ========================================
    if (level == "genes") {
        message(paste(
            "Generating DESeqDataSet with DESeq2",
            packageVersion("DESeq2")
        ))
        if (is.list(txi)) {
            # Create DESeqDataSet from tximport list by default
            dds <- DESeqDataSetFromTximport(
                txi = txi,
                colData = colData,
                # Use an empty design formula
                design = ~ 1L
            )
        } else {
            # Otherwise fall back to creating from the counts matrix
            dds <- DESeqDataSetFromMatrix(
                countData = counts,
                colData = colData,
                design = ~ 1L
            )
        }
        # Skip full DESeq2 calculations, for internal bcbio test data
        if (.dataHasVariation(dds)) {
            # Suppress warning about empty design formula
            dds <- suppressWarnings(DESeq(dds))
            if (isTRUE(vst)) {
                message("Applying variance-stabilizing transformation")
                vst <- assay(varianceStabilizingTransformation(dds))
            } else {
                vst <- NULL
            }
            if (isTRUE(rlog)) {
                message("Applying regularized log transformation")
                rlog <- assay(rlog(dds))
            } else {
                rlog <- NULL
            }
        } else {
            warning("Data has no variation. Skipping transformations.")
            dds <- estimateSizeFactors(dds)
            vst <- NULL
            rlog <- NULL
        }
        normalized <- counts(dds, normalized = TRUE)
    } else if (level == "transcripts") {
        normalized <- NULL
        vst <- NULL
        rlog <- NULL
    }

    # Assays ===================================================================
    assays <- list(
        counts = counts,
        tpm = tpm,
        length = length,
        normalized = normalized,
        vst = vst,
        rlog = rlog
    )

    # Metadata =================================================================
    metadata <- list(
        version = packageVersion,
        level = level,
        caller = caller,
        countsFromAbundance = countsFromAbundance,
        uploadDir = uploadDir,
        sampleDirs = sampleDirs,
        sampleMetadataFile = as.character(sampleMetadataFile),
        projectDir = projectDir,
        template = template,
        runDate = runDate,
        interestingGroups = interestingGroups,
        organism = as.character(organism),
        genomeBuild = as.character(genomeBuild),
        ensemblRelease = as.integer(ensemblRelease),
        rowRangesMetadata = rowRangesMetadata,
        gffFile = as.character(gffFile),
        tx2gene = tx2gene,
        lanes = lanes,
        yaml = yaml,
        dataVersions = dataVersions,
        programVersions = programVersions,
        bcbioLog = bcbioLog,
        bcbioCommandsLog = bcbioCommandsLog,
        allSamples = allSamples,
        call = match.call()
    )
    # Add user-defined custom metadata, if specified
    if (length(dots)) {
        assert_are_disjoint_sets(metadata, dots)
        metadata <- c(metadata, dots)
    }

    # Return ===================================================================
    .new.bcbioRNASeq(
        assays = assays,
        rowRanges = rowRanges,
        colData = colData,
        metadata = metadata,
        transgeneNames = transgeneNames,
        spikeNames = spikeNames
    )
}



# Validity Checks ==============================================================
setValidity(
    "bcbioRNASeq",
    function(object) {
        stopifnot(metadata(object)[["version"]] >= 0.2)
        assert_is_all_of(object, "RangedSummarizedExperiment")
        assert_has_dimnames(object)

        # Assays ===============================================================
        # Note that `rlog` and `vst` DESeqTransform objects are optional
        assert_is_subset(requiredAssays, assayNames(object))
        # Check that all assays are matrices
        assayCheck <- vapply(
            X = assays(object),
            FUN = is.matrix,
            FUN.VALUE = logical(1L),
            USE.NAMES = TRUE
        )
        if (!all(assayCheck)) {
            stop(paste(
                paste(
                    "Assays that are not matrix:",
                    toString(names(assayCheck[!assayCheck]))
                ),
                bcbioBase::updateMessage,
                sep = "\n"
            ))
        }

        # Gene-level specific
        if (metadata(object)[["level"]] == "genes") {
            assert_is_subset("normalized", names(assays(object)))
        }

        # Row data =============================================================
        assert_is_all_of(rowRanges(object), "GRanges")
        assert_is_all_of(rowData(object), "DataFrame")

        # Column data ==========================================================
        assert_are_disjoint_sets(colnames(colData(object)), legacyMetricsCols)

        # Metadata =============================================================
        metadata <- metadata(object)

        # Check that interesting groups defined in metadata are valid
        assert_is_subset(
            x = metadata[["interestingGroups"]],
            y = colnames(colData(object))
        )

        # Detect legacy metrics
        if (is.data.frame(metadata[["metrics"]])) {
            stop(paste(
                "`metrics` saved in `metadata()` instead of `colData()`.",
                bcbioBase::updateMessage
            ))
        }

        # Detect legacy slots
        legacyMetadata <- c(
            "design",
            "ensemblVersion",
            "gtf",
            "gtfFile",
            "missingGenes",
            "programs",
            "yamlFile"
        )
        intersect <- intersect(names(metadata), legacyMetadata)
        if (length(intersect)) {
            stop(paste(
                paste(
                    "Legacy metadata slots:",
                    toString(sort(intersect))
                ),
                bcbioBase::updateMessage,
                sep = "\n"
            ))
        }

        # v0.2.6: countsFromAbundance is now optional, since we're supporting
        # featureCounts aligned counts

        # Class checks (order independent)
        requiredMetadata <- list(
            allSamples = "logical",
            bcbioCommandsLog = "character",
            bcbioLog = "character",
            caller = "character",
            date = "Date",
            devtoolsSessionInfo = "session_info",
            ensemblRelease = "integer",
            genomeBuild = "character",
            gffFile = "character",
            interestingGroups = "character",
            lanes = "integer",
            level = "character",
            organism = "character",
            programVersions = "tbl_df",
            projectDir = "character",
            runDate = "Date",
            sampleDirs = "character",
            sampleMetadataFile = "character",
            template = "character",
            tx2gene = "data.frame",
            uploadDir = "character",
            utilsSessionInfo = "sessionInfo",
            version = "package_version",
            wd = "character",
            yaml = "list"
        )
        classChecks <- invisible(mapply(
            name <- names(requiredMetadata),
            expected <- requiredMetadata,
            MoreArgs = list(metadata = metadata),
            FUN = function(name, expected, metadata) {
                actual <- class(metadata[[name]])
                if (!length(intersect(expected, actual))) {
                    FALSE
                } else {
                    TRUE
                }
            },
            SIMPLIFY = TRUE,
            USE.NAMES = TRUE
        ))
        if (!all(classChecks)) {
            print(classChecks)
            stop(paste(
                "Metadata class checks failed.",
                bcbioBase::updateMessage,
                sep = "\n"
            ))
        }

        # Additional assert checks
        # caller
        assert_is_subset(
            x = metadata[["caller"]],
            y = validCallers
        )
        # level
        assert_is_subset(
            x = metadata[["level"]],
            y = c("genes", "transcripts")
        )
        # tx2gene
        tx2gene <- metadata[["tx2gene"]]
        assertIsTx2gene(tx2gene)

        TRUE
    }
)
