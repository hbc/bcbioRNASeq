#' @inherit bcbioRNASeq-class
#' @author Michael Steinbaugh, Lorena Pantano, Rory Kirchner, Victor Barrera
#' @export
#'
#' @description Simply point to the final upload directory generated by bcbio,
#'   and this generator function will take care of the rest.
#'
#' @details
#' The [bcbioRNASeq()] generator function automatically imports RNA-seq counts,
#' metadata, and the program versions used from a [bcbio][] RNA-seq run.
#'
#' [bcbio]: https://bcbio-nextgen.readthedocs.io
#'
#' @section Sample metadata:
#'
#' When loading a bcbio RNA-seq run, the sample metadata will be imported
#' automatically from the `project-summary.yaml` file in the final upload
#' directory. If you notice any typos in your metadata after completing the run,
#' these can be corrected by editing the YAML file.
#'
#' Alternatively, you can pass in a sample metadata file into the
#' [bcbioRNASeq()] function call using the `sampleMetadataFile` argument. This
#' requires either a CSV or Excel spreadsheet.
#'
#' The samples in the bcbio run must map to the `description` column. The values
#' provided in `description` must be unique. These values will be sanitized into
#' syntactically valid names (see [basejump::makeNames] for more
#' information), and assigned as the column names of the `bcbioRNASeq` object.
#' The original values are stored as the `sampleName` column in
#' [SummarizedExperiment::colData()], and are used for all plotting functions.
#' Do not attempt to set a `sampleID` column, as this is used internally by the
#' package.
#'
#' Here is a minimal example of a properly formatted sample metadata file:
#'
#' \tabular{ll}{
#'     description \tab genotype\cr
#'     sample1 \tab wildtype\cr
#'     sample2 \tab knockout\cr
#'     sample3 \tab wildtype\cr
#'     sample4 \tab knockout
#' }
#'
#' @section Valid names:
#'
#' R is strict about values that are considered valid for use in [base::names()]
#' and [base::dimnames()] (i.e. [base::rownames()] and [base::colnames()]).
#' Non-alphanumeric characters, spaces, and **dashes** are not valid. Use either
#' underscores or periods in place of dashes when working in R. Also note that
#' names should **not begin with a number**, and will be prefixed with an `X`
#' when sanitized. Consult the documentation in the [base::make.names()]
#' function for more information. We strongly recommend adhering to these
#' conventions when labeling samples, to help avoid unexpected downstream
#' behavior in R due to [base::dimnames()] mismatches.
#'
#' @section Genome build:
#'
#' Ensure that the organism and genome build used with bcio match correctly here
#' in the function call. In particular, for the legacy *Homo sapiens*
#' GRCh37/hg19 genome build, ensure that `genomeBuild = "GRCh37"`. Otherwise,
#' the genomic ranges set in [SummarizedExperiment::rowRanges()] will mismatch.
#' It is recommended for current projects that GRCh38/hg38 is used in place of
#' GRCh37/hg19 if possible.
#'
#' @section DESeq2:
#'
#' DESeq2 is run automatically when `bcbioRNASeq()` is called. Internally, this
#' automatically slots normalized counts into [SummarizedExperiment::assays()],
#' and optionally generates variance-stabilized `rlog` or `vst` counts,
#' depending on the call. When loading a dataset with a large number of samples
#' (i.e. > 50), we recommend disabling the `rlog` transformation, since it can
#' take a long time to compute.
#'
#' @section Remote connections:
#'
#' When working on a local machine, it is possible to load bcbio run data over a
#' remote connection using [sshfs][]. When loading a large number of samples, it
#' is preferable to call [bcbioRNASeq()] directly in R on the remote server, if
#' possible.
#'
#' [sshfs]: https://github.com/osxfuse/osxfuse/wiki/SSHFS
#'
#' @inheritParams params
#' @inheritParams basejump::params
#' @inheritParams basejump::makeSummarizedExperiment
#' @param uploadDir `string`. Path to final upload directory. This path is set
#'   when running "`bcbio_nextgen -w template`".
#' @param level `string`. Import counts at gene level ("`genes`"; *default*) or
#'   transcript level ("`transcripts`"; *advanced use*). Only
#'   tximport-compatible callers (e.g. salmon, kallisto, sailfish) can be loaded
#'   at transcript level. Aligned counts from featureCounts-compatible callers
#'   (e.g. STAR, HISAT2) can only be loaded at gene level.
#' @param caller `string`. Expression caller:
#'   - "`salmon`" (*default*): [Salmon](https://combine-lab.github.io/salmon)
#'     alignment-free, quasi-mapped counts.
#'   - "`kallisto`". [Kallisto](https://pachterlab.github.io/kallisto)
#'     alignment-free, pseudo-aligned counts.
#'   - "`sailfish`".
#'     [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish)
#'     alignment-free, lightweight counts.
#'   - "`star`": [STAR](https://github.com/alexdobin/STAR)
#'     (Spliced Transcripts Alignment to a Reference) aligned counts.
#'   - "`hisat2`": [HISAT2](https://ccb.jhu.edu/software/hisat2)
#'     (Hierarchical Indexing for Spliced Alignment of Transcripts) graph-based
#'     aligned counts.
#' @param samples `character` or `NULL`. Specify a subset of samples to load.
#'   The names must match the `description` specified in the bcbio YAML
#'   metadata. If a `sampleMetadataFile` is provided, that will take priority
#'   for sample selection. Typically this can be left unset.
#' @param censorSamples `character` or `NULL`. Samples to exclude from the
#'   analysis.
#' @param sampleMetadataFile `string` or `NULL`. Custom metadata file containing
#'   sample information. Otherwise defaults to sample metadata saved in the YAML
#'   file. Remote URLs are supported. Typically this can be left unset.
#' @param organism `string` or `NULL`. Organism name. Use the full Latin name
#'   (e.g. "Homo sapiens"), since this will be input downstream to AnnotationHub
#'   and ensembldb, unless `gffFile` is set. If left `NULL` (*not recommended*),
#'   the function call will skip loading gene/transcript-level annotations into
#'   [rowRanges()]. This can be useful for poorly annotation genomes or
#'   experiments involving multiple genomes.
#' @param genomeBuild `string` or `NULL`. Ensembl genome build name (e.g.
#'   "GRCh38"). This will be passed to AnnotationHub for `EnsDb` annotation
#'   matching, unless `gffFile` is set.
#' @param ensemblRelease `scalar integer` or `NULL`. Ensembl release version. If
#'   unset, defaults to current release, and does not typically need to be
#'   user-defined. Passed to AnnotationHub for `EnsDb` annotation matching,
#'   unless `gffFile` is set.
#' @param gffFile `string` or `NULL`. By default, we recommend leaving this
#'   `NULL` for genomes that are supported on Ensembl. In this case, the row
#'   annotations ([SummarizedExperiment::rowRanges()]) will be obtained
#'   automatically from Ensembl by passing the `organism`, `genomeBuild`, and
#'   `ensemblRelease` arguments to AnnotationHub and ensembldb. For a genome
#'   that is not supported on Ensembl and/or AnnotationHub, a GFF/GTF (General
#'   Feature Format) file is required. Generally, we recommend using a GTF
#'   (GFFv2) file here over a GFF3 file if possible, although all GFF formats
#'   are supported. The function will internally generate a `TxDb` containing
#'   transcript-to-gene mappings and construct a `GRanges` object containing the
#'   genomic ranges.
#' @param countsFromAbundance `string`. Whether to generate estimated counts
#'   using abundance estimates (*recommended by default*). `lengthScaledTPM` is
#'   a suitable default, and counts are scaled using the average transcript
#'   length over samples and then the library size. Refer to
#'   [tximport::tximport()] for more information on this parameter, but it
#'   should only ever be changed when loading some datasets at transcript level
#'   (e.g. for DTU analsyis).
#' @param vst `boolean`. Calculate variance-stabilizing transformation using
#'   [DESeq2::varianceStabilizingTransformation()]. Recommended by default
#'   for visualization.
#' @param rlog `boolean`. Calcualte regularized log transformation using
#'   [DESeq2::rlog()]. This calculation is slow for large datasets and now
#'   discouraged by default for visualization.
#'
#' @return `bcbioRNASeq`.
#'
#' @seealso
#' - `.S4methods(class = "bcbioRNASeq")`.
#' - [SummarizedExperiment::SummarizedExperiment()].
#' - [methods::initialize()].
#' - [methods::validObject()].
#' - [BiocGenerics::updateObject()].
#'
#' @examples
#' uploadDir <- system.file("extdata/bcbio", package = "bcbioRNASeq")
#'
#' ## Gene level.
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "genes",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' print(object)
#'
#' ## Transcript level.
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "transcripts",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' print(object)
bcbioRNASeq <- function(
    uploadDir,
    level = c("genes", "transcripts"),
    caller = c("salmon", "kallisto", "sailfish", "star", "hisat2"),
    samples = NULL,
    censorSamples = NULL,
    sampleMetadataFile = NULL,
    organism = NULL,
    genomeBuild = NULL,
    ensemblRelease = NULL,
    gffFile = NULL,
    transgeneNames = NULL,
    spikeNames = NULL,
    countsFromAbundance = "lengthScaledTPM",
    vst = TRUE,
    rlog = FALSE,
    interestingGroups = "sampleName",
    ...
) {
    # Legacy arguments ---------------------------------------------------------
    # nocov start
    call <- match.call()
    # annotable
    if ("annotable" %in% names(call)) {
        stop("`annotable` is defunct. Consider using `gffFile` instead.")
    }
    # ensemblVersion
    if ("ensemblVersion" %in% names(call)) {
        stop("Use `ensemblRelease` instead of `ensemblVersion`.")
    }
    # transformationLimit
    if ("transformationLimit" %in% names(call)) {
        stop(paste(
            "`transformationLimit` is deprecated in favor of",
            "separate `vst` and `rlog` arguments."
        ))
    }
    rm(call)
    # nocov end

    # Assert checks ------------------------------------------------------------
    assert_is_a_string(uploadDir)
    assert_all_are_dirs(uploadDir)
    level <- match.arg(level)
    caller <- match.arg(caller)
    if (level == "transcripts") {
        assert_is_subset(caller, tximportCallers)
    }
    assert_is_any_of(samples, c("character", "NULL"))
    assert_is_any_of(censorSamples, c("character", "NULL"))
    assertIsStringOrNULL(sampleMetadataFile)
    assertIsStringOrNULL(organism)
    assertIsAnImplicitIntegerOrNULL(ensemblRelease)
    assertIsStringOrNULL(genomeBuild)
    assert_is_any_of(transgeneNames, c("character", "NULL"))
    assert_is_any_of(spikeNames, c("character", "NULL"))
    assertIsStringOrNULL(gffFile)
    if (is_a_string(gffFile)) {
        assert_all_are_existing_files(gffFile)
    }
    match.arg(
        arg = countsFromAbundance,
        choices = eval(formals(tximport)[["countsFromAbundance"]])
    )
    assert_is_a_bool(vst)
    assert_is_a_bool(rlog)
    assert_is_character(interestingGroups)

    # Directory paths ----------------------------------------------------------
    uploadDir <- realpath(uploadDir)
    projectDir <- projectDir(uploadDir)
    sampleDirs <- sampleDirs(uploadDir)

    # Project summary YAML -----------------------------------------------------
    yamlFile <- file.path(projectDir, "project-summary.yaml")
    yaml <- import(yamlFile)
    assert_is_list(yaml)

    # bcbio run information ----------------------------------------------------
    dataVersions <-
        readDataVersions(file.path(projectDir, "data_versions.csv"))
    assert_is_all_of(dataVersions, "DataFrame")

    programVersions <-
        readProgramVersions(file.path(projectDir, "programs.txt"))
    assert_is_all_of(programVersions, "DataFrame")

    bcbioLog <-
        import(file.path(projectDir, "bcbio-nextgen.log"))
    assert_is_character(bcbioLog)

    bcbioCommandsLog <-
        import(file.path(projectDir, "bcbio-nextgen-commands.log"))
    assert_is_character(bcbioCommandsLog)

    # Transcript-to-gene mappings ----------------------------------------------
    tx2gene <- readTx2Gene(
        file = file.path(projectDir, "tx2gene.csv"),
        organism = organism,
        genomeBuild = genomeBuild,
        ensemblRelease = ensemblRelease
    )
    assert_is_all_of(tx2gene, "Tx2Gene")

    # Sequencing lanes ---------------------------------------------------------
    lanes <- detectLanes(sampleDirs)
    assert_is_integer(lanes)

    # Samples ------------------------------------------------------------------
    # Get the sample data.
    if (is_a_string(sampleMetadataFile)) {
        # Normalize path of local file.
        if (file.exists(sampleMetadataFile)) {
            sampleMetadataFile <- realpath(sampleMetadataFile)
        }
        # User-defined external file.
        # Note that `readSampleData()` also supports URLs.
        sampleData <- readSampleData(file = sampleMetadataFile, lanes = lanes)
    } else {
        # Automatic metadata from YAML file.
        sampleData <- getSampleDataFromYAML(yaml)
    }
    assert_is_subset(rownames(sampleData), names(sampleDirs))

    # Subset the sample directories, if necessary.
    if (is.character(samples) || is.character(censorSamples)) {
        # Matching against the YAML "description" input here.
        description <- as.character(sampleData[["description"]])
        assert_is_non_empty(description)
        if (is.character(samples)) {
            assert_is_subset(samples, description)
        } else {
            samples <- description
        }
        if (is.character(censorSamples)) {
            assert_is_subset(censorSamples, samples)
            samples <- setdiff(samples, censorSamples)
        }
        assert_is_non_empty(samples)
        sampleData <- sampleData %>%
            as_tibble() %>%
            filter(!!sym("description") %in% !!samples) %>%
            as("DataFrame")
    }
    samples <- rownames(sampleData)
    # Require at least 2 samples.
    assert_that(length(samples) >= 2L)
    assert_is_subset(samples, names(sampleDirs))
    assertAreValidNames(samples)
    if (length(samples) < length(sampleDirs)) {
        message(paste(
            "Loading a subset of samples:",
            str_trunc(toString(samples), width = 80L),
            sep = "\n"
        ))
        allSamples <- FALSE
    } else {
        allSamples <- TRUE
    }
    sampleDirs <- sampleDirs[samples]

    # Column data --------------------------------------------------------------
    # Sample metrics. Note that sample metrics used for QC plots are not
    # currently generated when using fast RNA-seq workflow. This depends upon
    # MultiQC and aligned counts generated with STAR.
    colData <- getMetricsFromYAML(yaml)
    if (has_length(colData)) {
        assert_are_disjoint_sets(colnames(colData), colnames(sampleData))
        assert_is_subset(rownames(sampleData), rownames(colData))
        colData <- colData[rownames(sampleData), , drop = FALSE]
        colData <- cbind(colData, sampleData)
    } else {
        message("Fast mode detected. No metrics were calculated.")
        colData <- sampleData
    }
    assert_is_all_of(colData, "DataFrame")
    assert_are_identical(samples, rownames(colData))

    # Assays -------------------------------------------------------------------
    assays <- list()
    # Use tximport by default for transcript-aware callers.
    # Otherwise, resort to loading the featureCounts aligned counts data.
    if (caller %in% tximportCallers) {
        if (level == "transcripts") {
            txOut <- TRUE
        } else {
            txOut <- FALSE
        }
        txi <- .tximport(
            sampleDirs = sampleDirs,
            type = caller,
            txOut = txOut,
            countsFromAbundance = countsFromAbundance,
            tx2gene = tx2gene
        )
        # Raw counts. Length scaled by default (see `countsFromAbundance`).
        # These counts are expected to be non-integer.
        assays[["counts"]] <- txi[["counts"]]
        # Transcripts per million.
        assays[["tpm"]] <- txi[["abundance"]]
        # Average transcript lengths.
        assays[["avgTxLength"]] <- txi[["length"]]
    } else if (caller %in% featureCountsCallers) {
        txi <- NULL
        countsFromAbundance <- "no"
        assert_are_identical(level, "genes")
        # Load up the featureCounts aligned counts matrix.
        counts <- import(file = file.path(projectDir, "combined.counts"))
        assert_is_matrix(counts)
        colnames(counts) <- makeNames(colnames(counts))
        # Subset the combined matrix to match the samples.
        assert_is_subset(samples, colnames(counts))
        counts <- counts[, samples, drop = FALSE]
        # Raw counts. These counts are expected to be integer.
        assays[["counts"]] <- counts
    }

    assert_are_identical(names(assays)[[1L]], "counts")
    assert_are_identical(colnames(assays[[1L]]), rownames(colData))

    # Row data -----------------------------------------------------------------
    # Annotation priority:
    # 1. GTF/GFF file. Use the bcbio GTF if possible.
    # 2. AnnotationHub.
    #    - Requires `organism` to be declared.
    #    - Ensure that Ensembl release and genome build match.
    # 3. Fall back to slotting empty ranges. This is offered as support for
    #    complex datasets (e.g. multiple organisms).

    # Attempt to use bcbio GTF automatically.
    # Consider warning the user here instead of messaging.
    if (is.null(gffFile)) {
        gffFile <- getGTFFileFromYAML(yaml)
        if (!file.exists(gffFile)) {
            message(paste0("bcbio GTF file missing:", "\n  ", gffFile))
        }
        gffFile <- NULL
    }

    # Fetch the genomic ranges.
    if (is_a_string(gffFile)) {
        # GTF/GFF file.
        message("Using `makeGRangesFromGFF()` for annotations.")
        if (file.exists(gffFile)) {
            gffFile <- realpath(gffFile)
        }
        rowRanges <- makeGRangesFromGFF(file = gffFile, level = level)
    } else if (
        is_a_string(organism) &&
        is.numeric(ensemblRelease)
    ) {
        # AnnotationHub (ensembldb).
        message("Using `makeGRangesFromEnsembl()` for annotations.")
        rowRanges <- makeGRangesFromEnsembl(
            organism = organism,
            level = level,
            genomeBuild = genomeBuild,
            release = ensemblRelease
        )
    } else {
        message("Slotting empty ranges into rowRanges().")
        rowRanges <- emptyRanges(rownames(assays[[1L]]))
    }
    assert_is_all_of(rowRanges, "GRanges")

    # Attempt to get genome build and Ensembl release if not declared.
    # Note that these will remain NULL when using GTF file (see above).
    if (is.null(genomeBuild)) {
        genomeBuild <- metadata(rowRanges)[["genomeBuild"]]
    }
    if (is.null(ensemblRelease)) {
        ensemblRelease <- metadata(rowRanges)[["ensemblRelease"]]
    }

    # Metadata -----------------------------------------------------------------
    # Interesting groups.
    interestingGroups <- camel(interestingGroups)
    assert_is_subset(interestingGroups, colnames(colData))

    # Organism.
    # Attempt to detect automatically if not declared by user.
    if (is.null(organism)) {
        organism <- tryCatch(
            expr = detectOrganism(rownames(assays[[1L]])),
            error = function(e) {
                warning(paste(
                    "Failed to detect organism automatically.",
                    "Specify with `organism` argument."
                ))
            }
        )
    }

    metadata <- list(
        version = packageVersion,
        level = level,
        caller = caller,
        countsFromAbundance = countsFromAbundance,
        uploadDir = uploadDir,
        sampleDirs = sampleDirs,
        sampleMetadataFile = as.character(sampleMetadataFile),
        projectDir = projectDir,
        runDate = runDate(projectDir),
        interestingGroups = interestingGroups,
        organism = as.character(organism),
        genomeBuild = as.character(genomeBuild),
        ensemblRelease = as.integer(ensemblRelease),
        gffFile = as.character(gffFile),
        tx2gene = tx2gene,
        lanes = lanes,
        yaml = yaml,
        dataVersions = dataVersions,
        programVersions = programVersions,
        bcbioLog = bcbioLog,
        bcbioCommandsLog = bcbioCommandsLog,
        allSamples = allSamples,
        call = match.call()
    )

    # Generate bcbioRNASeq object ----------------------------------------------
    bcb <- .new.bcbioRNASeq(
        assays = assays,
        rowRanges = rowRanges,
        colData = colData,
        metadata = metadata,
        transgeneNames = transgeneNames,
        spikeNames = spikeNames
    )

    # DESeq2 normalizations ----------------------------------------------------
    if (level == "genes") {
        dds <- as(bcb, "DESeqDataSet")

        # Calculate size factors for normalized counts.
        message("Calculating normalized counts.")
        dds <- estimateSizeFactors(dds)
        assays(bcb)[["normalized"]] <- counts(dds, normalized = TRUE)

        # Skip full DESeq2 calculations (for internal bcbio test data).
        if (.dataHasVariation(dds)) {
            message("Calculating transformations.")
            # Expect warning about the empty design formula.
            dds <- suppressWarnings(DESeq(dds))
            if (isTRUE(vst)) {
                message("Applying variance-stabilizing transformation.")
                assays(bcb)[["vst"]] <-
                    assay(varianceStabilizingTransformation(dds))
            }
            if (isTRUE(rlog)) {
                message("Applying regularized log transformation.")
                assays(bcb)[["rlog"]] <- assay(rlog(dds))
            }
        } else {
            # nocov start
            # This step is covered by bcbio pipeline tests.
            message("Data has no variation. Skipping transformations.")
            # nocov end
        }

        # Calculate FPKM.
        # Skip this step if we've slotted empty ranges.
        if (length(unique(width(rowRanges(dds)))) > 1L) {
            message("Calculating FPKM.")
            assays(bcb)[["fpkm"]] <- fpkm(dds)
        } else {
            message(paste(
                "rowRanges() contains empty ranges.",
                "Skipping FPKM calculation."
            ))
        }
    }

    # Return -------------------------------------------------------------------
    assertHasValidDimnames(bcb)
    validObject(bcb)
    bcb
}



.new.bcbioRNASeq <-  # nolint
    function(
        assays,
        rowRanges,
        colData,
        metadata,
        transgeneNames = NULL,
        spikeNames = NULL
    ) {
        new(
            Class = "bcbioRNASeq",
            makeSummarizedExperiment(
                assays = assays,
                rowRanges = rowRanges,
                colData = colData,
                metadata = metadata,
                transgeneNames = transgeneNames,
                spikeNames = spikeNames
            )
        )
    }
