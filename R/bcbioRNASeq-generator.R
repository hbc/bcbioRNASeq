#' `bcbioRNASeq` Generator
#'
#' @family S4 Object
#' @author Michael Steinbaugh, Lorena Pantano, Rory Kirchner, Victor Barrera
#' @export
#'
#' @description
#' Simply point to the final upload directory generated by
#' [bcbio](https://bcbio-nextgen.readthedocs.io/), and this constructor function
#' will take care of the rest. It automatically imports RNA-seq counts,
#' metadata, and the program versions used.
#'
#' @details
#' This class contains raw read counts and length-scaled
#' transcripts per million (TPM) generated by [tximport::tximport()]. Counts can
#' be loaded at gene or transcript level.
#'
#' @section Metadata:
#'
#' The [metadata()] slot contains:
#'
#' - Sample quality control metrics.
#' - Ensembl annotations.
#' - Server run paths.
#' - R session information (e.g. [utils::sessionInfo()]).
#'
#' @section Valid names:
#'
#' R is strict about values that are considered valid for use in [names()] and
#' [dimnames()] (i.e. [rownames()] and [colnames()]). Non-alphanumeric
#' characters, spaces, and **dashes** are not valid. Use either underscores or
#' periods in place of dashes when working in R. Also note that names should
#' **not begin with a number**, and will be prefixed with an `X` when sanitized.
#' Consult the documentation in the [base::make.names()] function for more
#' information. We strongly recommend adhering to these conventions when
#' labeling samples, to help avoid unexpected downstream behavior in R due to
#' [dimnames()] mismatches.
#'
#' @section Genome build:
#'
#' Ensure that the organism and genome build used with bcio match correctly
#' here in the function call. In particular, for the legacy *Homo sapiens*
#' GRCh37/hg19 genome build, ensure that `genomeBuild = "GRCh37"`. Otherwise,
#' the genomic ranges set in [rowRanges()] will mismatch. It is recommended
#' for current projects that GRCh38/hg38 is used in place of GRCh37/hg19
#' if possible.
#'
#' @section DESeq2:
#'
#' DESeq2 is run automatically when `bcbioRNASeq()` is called. Internally, this
#' automatically slots normalized counts into [assays()], and optionally
#' generates variance-stabilized `rlog` or `vst` counts, depending on the call.
#' When loading a dataset with a large number of samples (i.e. > 50), we
#' recommend disabling the `rlog` transformation, since it can take a long time
#' to compute.
#'
#' @section Remote data:
#'
#' When working in RStudio, we recommend connecting to the bcbio run directory
#' as a remote connection over
#' [sshfs](https://github.com/osxfuse/osxfuse/wiki/SSHFS). When loading a large
#' number of samples, it is preferable to call [bcbioRNASeq()] directly in R
#' on the remote server, if possible.
#'
#' @inheritParams basejump::makeSummarizedExperiment
#' @inheritParams general
#' @param uploadDir `string`. Path to final upload directory. This path is set
#'   when running "`bcbio_nextgen -w template`".
#' @param level `string`. Import counts at gene level ("`genes`"; *default*) or
#'   transcript level ("`transcripts`"; *advanced use*).
#' @param caller `string`. Expression caller:
#'   - "`salmon`" (*default*): [Salmon](https://combine-lab.github.io/salmon)
#'     alignment-free, quasi-mapped counts.
#'   - "`kallisto`". [Kallisto](https://pachterlab.github.io/kallisto)
#'     alignment-free, pseudo-aligned counts.
#'   - "`sailfish`".
#'     [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish)
#'     alignment-free, lightweight counts.
#'   - "`star`": [STAR](https://github.com/alexdobin/STAR)
#'     (Spliced Transcripts Alignment to a Reference) aligned counts.
#'   - "`hisat2`": [HISAT2](https://ccb.jhu.edu/software/hisat2)
#'     (Hierarchical Indexing for Spliced Alignment of Transcripts) graph-based
#'     aligned counts.
#' @param samples `character` or `NULL`. Specify a subset of samples to load.
#'   The names must match the `description` specified in the bcbio YAML
#'   metadata. If a `sampleMetadataFile` is provided, that will take priority
#'   for sample selection. Typically this can be left unset.
#' @param censorSamples `character` or `NULL`. Samples to exclude from the
#'   analysis.
#' @param sampleMetadataFile `string` or `NULL`. Custom metadata file containing
#'   sample information. Otherwise defaults to sample metadata saved in the YAML
#'   file. Remote URLs are supported. Typically this can be left unset.
#' @param organism `string` or `NULL`. Organism name. Use the full Latin name
#'   (e.g. "Homo sapiens"), since this will be input downstream to AnnotationHub
#'   and ensembldb, unless `gffFile` is set. If left `NULL` (*not recommended*),
#'   the function call will skip loading gene/transcript-level annotations into
#'   [rowRanges()]. This can be useful for poorly annotation genomes or
#'   experiments involving multiple genomes.
#' @param genomeBuild `string` or `NULL`. Ensembl genome build name (e.g.
#'   "GRCh38"). This will be passed to AnnotationHub for `EnsDb` annotation
#'   matching, unless `gffFile` is set.
#' @param ensemblRelease `scalar integer` or `NULL`. Ensembl release version. If
#'   unset, defaults to current release, and does not typically need to be
#'   user-defined. Passed to AnnotationHub for `EnsDb` annotation matching,
#'   unless `gffFile` is set.
#' @param gffFile `string` or `NULL`. By default, we recommend leaving this
#'   `NULL` for genomes that are supported on Ensembl. In this case, the row
#'   annotations ([rowRanges()]) will be obtained automatically from Ensembl by
#'   passing the `organism`, `genomeBuild`, and `ensemblRelease` arguments to
#'   AnnotationHub and ensembldb. For a genome that is not supported on Ensembl
#'   and/or AnnotationHub, a GFF/GTF (General Feature Format) file is required.
#'   Generally, we recommend using a GTF (GFFv2) file here over a GFF3 file if
#'   possible, although all GFF formats are supported. The function will
#'   internally generate a `TxDb` containing transcript-to-gene mappings and
#'   construct a `GRanges` object containing the genomic ranges ([rowRanges()]).
#' @param vst `boolean`. Calculate variance-stabilizing transformation using
#'   [DESeq2::varianceStabilizingTransformation()]. Recommended by default
#'   for visualization.
#' @param rlog `boolean`. Calcualte regularized log transformation using
#'   [DESeq2::rlog()]. This calculation is slow for large datasets and now
#'   discouraged by default for visualization.
#'
#' @return `bcbioRNASeq`.
#'
#' @seealso
#' - [SummarizedExperiment::SummarizedExperiment()].
#' - [methods::initialize()].
#' - [methods::validObject()].
#' - [BiocGenerics::updateObject()].
#' - `.S4methods(class = "bcbioRNASeq")`.
#'
#' @examples
#' uploadDir <- system.file("extdata/bcbio", package = "bcbioRNASeq")
#'
#' # Gene level
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "genes",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(object)
#' is(object, "RangedSummarizedExperiment")
#' validObject(object)
#'
#' # Transcript level
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "transcripts",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(object)
#' validObject(object)
bcbioRNASeq <- function(
    uploadDir,
    level = c("genes", "transcripts"),
    caller = c("salmon", "kallisto", "sailfish", "star", "hisat2"),
    interestingGroups = "sampleName",
    samples = NULL,
    censorSamples = NULL,
    sampleMetadataFile = NULL,
    organism = NULL,
    genomeBuild = NULL,
    ensemblRelease = NULL,
    gffFile = NULL,
    transgeneNames = NULL,
    spikeNames = NULL,
    vst = TRUE,
    rlog = FALSE,
    ...
) {
    call <- match.call()

    # Legacy arguments ---------------------------------------------------------
    # nocov start
    # annotable
    if ("annotable" %in% names(call)) {
        stop("`annotable` is defunct. Consider using `gffFile` instead.")
    }
    # ensemblVersion
    if ("ensemblVersion" %in% names(call)) {
        warning("Use `ensemblRelease` instead of `ensemblVersion`")
        ensemblRelease <- call[["ensemblVersion"]]
    }
    # organism
    if (!"organism" %in% names(call)) {
        message(paste(
            "`organism` is recommended for defining",
            "annotations in `rowRanges()`"
        ))
    }
    # transformationLimit
    if ("transformationLimit" %in% names(call)) {
        stop(paste(
            "`transformationLimit` is deprecated in favor of",
            "separate `vst` and `rlog` arguments"
        ))
    }
    # nocov end

    # Assert checks ------------------------------------------------------------
    assert_is_a_string(uploadDir)
    assert_all_are_dirs(uploadDir)
    level <- match.arg(level)
    caller <- match.arg(caller)
    if (level == "transcripts") {
        assert_is_subset(caller, tximportCallers)
    }
    assertIsAStringOrNULL(sampleMetadataFile)
    assert_is_any_of(samples, c("character", "NULL"))
    assert_is_any_of(censorSamples, c("character", "NULL"))
    assert_is_character(interestingGroups)
    assertIsAStringOrNULL(organism)
    assertIsAnImplicitIntegerOrNULL(ensemblRelease)
    assertIsAStringOrNULL(genomeBuild)
    assert_is_any_of(transgeneNames, c("character", "NULL"))
    assert_is_any_of(spikeNames, c("character", "NULL"))
    assertIsAStringOrNULL(gffFile)
    if (is_a_string(gffFile)) {
        assert_all_are_existing_files(gffFile)
    }
    assert_is_a_bool(vst)
    assert_is_a_bool(rlog)

    # Directory paths ----------------------------------------------------------
    uploadDir <- normalizePath(uploadDir, winslash = "/", mustWork = TRUE)
    projectDir <- projectDir(uploadDir)
    sampleDirs <- sampleDirs(uploadDir)

    # Run date and template name -----------------------------------------------
    # Get run date and template name from project directory.
    # This information will be stashed in `metadata()`.
    match <- str_match(
        string = basename(projectDir),
        pattern = projectDirPattern
    )
    runDate <- as.Date(match[[2L]])
    template <- match[[3L]]
    rm(match)

    # Project summary YAML -----------------------------------------------------
    yamlFile <- file.path(projectDir, "project-summary.yaml")
    assert_all_are_existing_files(yamlFile)
    yaml <- readYAML(yamlFile)

    # bcbio run information ----------------------------------------------------
    dataVersions <- readDataVersions(
        file = file.path(projectDir, "data_versions.csv")
    )
    assert_is_tbl_df(dataVersions)

    programVersions <- readProgramVersions(
        file = file.path(projectDir, "programs.txt")
    )
    assert_is_tbl_df(programVersions)

    bcbioLog <- readLog(
        file = file.path(projectDir, "bcbio-nextgen.log")
    )
    assert_is_character(bcbioLog)

    bcbioCommandsLog <- readLog(
        file = file.path(projectDir, "bcbio-nextgen-commands.log")
    )
    assert_is_character(bcbioCommandsLog)

    # Sequencing lanes ---------------------------------------------------------
    if (any(grepl(x = sampleDirs, pattern = lanePattern))) {
        # nocov start
        lanes <- str_match(names(sampleDirs), lanePattern) %>%
            .[, 2L] %>%
            unique() %>%
            length()
        message(paste(
            lanes, "sequencing lane detected", "(technical replicates)"
        ))
        # nocov end
    } else {
        lanes <- 1L
    }
    assert_is_an_integer(lanes)

    # Column data --------------------------------------------------------------
    # TODO Assert that `description` matches `names(sampleNames)`.
    # Consider running this against user-defined sample metadata too.

    colData <- readYAMLSampleData(yamlFile)

    # Require that all sample IDs defined here in the column data (rownames)
    # match the names in the `sampleDirs` vector.
    setdiff <- setdiff(names(sampleDirs), rownames(colData))
    if (length(setdiff)) {
        stop(paste("Mismatch detected in sampleDirs and colData:", setdiff))
    }
    assert_are_identical(names(sampleDirs), rownames(colData))

    # Subset the samples.
    if (is_a_string(sampleMetadataFile)) {
        # Replace columns with external, user-defined metadata, if desired. This
        # is nice for correcting metadata issues that aren't easy to fix by
        # editing the bcbio YAML output.
        userColData <- readSampleData(sampleMetadataFile, lanes = lanes)
        # Drop columns that are defined from the auto metadata.
        setdiff <- setdiff(colnames(colData), colnames(userColData))
        # Note that we're allowing the user to subset the samples by the
        # metadata input here.
        colData <- colData[rownames(userColData), setdiff, drop = FALSE]
        colData <- cbind(userColData, colData)
    } else if (is.character(samples)) {
        assert_is_subset(samples, colData[["description"]])
        colData <- colData %>%
            .[.[["description"]] %in% samples, , drop = FALSE]
    } else if (is.character(censorSamples)) {
        colData <- colData %>%
            .[!.[["description"]] %in% censorSamples, , drop = FALSE]
    }

    # Sanitize the column data to only contain factors, before adding our
    # metrics calculations.
    colData <- sanitizeSampleData(colData)

    # Sample metrics. Note that sample metrics used for QC plots are not
    # currently generated when using fast RNA-seq workflow. This depends upon
    # MultiQC and aligned counts generated with STAR.
    metrics <- readYAMLSampleMetrics(yamlFile)
    if (length(metrics)) {
        assert_is_all_of(metrics, "DataFrame")
        assert_are_disjoint_sets(colnames(colData), colnames(metrics))
        # Subset metrics to match the colData, since we may have subset the
        # number of samples above.
        metrics <- metrics[rownames(colData), , drop = FALSE]
        colData <- cbind(colData, metrics)
    } else {
        message("Fast mode detected. No metrics were calculated.")  # nocov
    }

    # Subset sample directories by metadata ------------------------------------
    samples <- rownames(colData)
    assertAllAreValidNames(samples)
    assert_is_subset(samples, names(sampleDirs))
    if (length(samples) < length(sampleDirs)) {
        message(paste(
            "Loading a subset of samples:",
            str_trunc(toString(samples), width = 80L),
            sep = "\n"
        ))
        allSamples <- FALSE
        sampleDirs <- sampleDirs[samples]
    } else {
        allSamples <- TRUE
    }

    # Interesting groups -------------------------------------------------------
    interestingGroups <- camel(interestingGroups)
    assert_is_subset(interestingGroups, colnames(colData))

    # Transcript-to-gene mappings ----------------------------------------------
    tx2geneFile <- file.path(projectDir, "tx2gene.csv")
    assert_all_are_existing_files(tx2geneFile)
    tx2gene <- readTx2gene(tx2geneFile)

    # Read counts --------------------------------------------------------------
    # Use tximport by default for transcript-aware callers.
    # Otherwise, resort to loading the featureCounts aligned counts data.
    if (caller %in% tximportCallers) {
        # tximport
        if (level == "transcripts") {
            txOut <- TRUE
        } else {
            txOut <- FALSE
        }
        txi <- .tximport(
            sampleDirs = sampleDirs,
            type = caller,
            txIn = TRUE,
            txOut = txOut,
            tx2gene = tx2gene
        )
        # `tpm` (abundance): transcripts per million.
        tpm <- txi[["abundance"]]
        # `counts`: raw counts
        counts <- txi[["counts"]]
        # Length: average transcript length.
        length <- txi[["length"]]
        # `countsFromAbundance`: `string` describing how TPMs were calculated.
        countsFromAbundance <- txi[["countsFromAbundance"]]
    } else if (caller %in% featureCountsCallers) {
        tpm <- NULL
        length <- NULL
        countsFromAbundance <- NULL
        # Load up the featureCounts aligned counts matrix.
        counts <- import(file.path(projectDir, "combined.counts"))
        assert_is_matrix(counts)
        colnames(counts) <- makeNames(colnames(counts))
        # Subset the combined matrix to match the samples.
        assert_is_subset(names(sampleDirs), colnames(counts))
        counts <- counts[, names(sampleDirs), drop = FALSE]
    }

    # Ensure `colData` matches the colnames in `assays()`.
    colData <- colData[colnames(counts), , drop = FALSE]

    # Row data -----------------------------------------------------------------
    rowRangesMetadata <- NULL
    if (is_a_string(gffFile)) {
        message("Using `makeGRangesFromGFF()` for annotations")
        rowRanges <- makeGRangesFromGFF(gffFile)
    } else if (is_a_string(organism)) {
        # Using AnnotationHub/ensembldb to obtain the annotations.
        message("Using `makeGRangesFromEnsembl()` for annotations")
        ah <- makeGRangesFromEnsembl(
            organism = organism,
            level = level,
            build = genomeBuild,
            release = ensemblRelease,
            metadata = TRUE
        )
        assert_is_list(ah)
        assert_are_identical(names(ah), c("data", "metadata"))
        rowRanges <- ah[["data"]]
        assert_is_all_of(rowRanges, "GRanges")
        rowRangesMetadata <- ah[["metadata"]]
        assert_is_data.frame(rowRangesMetadata)
        genomeBuild <- rowRangesMetadata %>%
            filter(!!sym("name") == "genome_build") %>%
            pull("value")
        assert_is_a_string(genomeBuild)
    } else {
        rowRanges <- emptyRanges(rownames(counts))
    }

    # Gene-level variance stabilization ----------------------------------------
    if (level == "genes") {
        message(paste(
            "Generating DESeqDataSet with DESeq2",
            packageVersion("DESeq2")
        ))
        if (is.list(txi)) {
            # Create `DESeqDataSet` from `tximport()` return `list` by default.
            # Note that we're setting an empty design formula here.
            dds <- DESeqDataSetFromTximport(
                txi = txi,
                colData = colData,
                design = ~ 1L
            )
        } else {
            # Otherwise fall back to creating from the counts matrix.
            # This applies to datasets using aligned counts (e.g. STAR).
            dds <- DESeqDataSetFromMatrix(
                countData = counts,
                colData = colData,
                design = ~ 1L
            )
        }
        # Skip full DESeq2 calculations, for internal bcbio test data.
        if (.dataHasVariation(dds)) {
            # Suppress expected warnings about the design formula.
            dds <- suppressWarnings(DESeq(dds))
            if (isTRUE(vst)) {
                message("Applying variance-stabilizing transformation")
                vst <- assay(varianceStabilizingTransformation(dds))
            } else {
                vst <- NULL
            }
            if (isTRUE(rlog)) {
                message("Applying regularized log transformation")
                rlog <- assay(rlog(dds))
            } else {
                rlog <- NULL
            }
        } else {
            # This step is covered by the bcbio pipeline tests.
            # nocov start
            warning("Data has no variation. Skipping transformations.")
            dds <- estimateSizeFactors(dds)
            vst <- NULL
            rlog <- NULL
            # nocov end
        }
        normalized <- counts(dds, normalized = TRUE)
    } else if (level == "transcripts") {
        normalized <- NULL
        vst <- NULL
        rlog <- NULL
    }

    # Assays -------------------------------------------------------------------
    assays <- list(
        counts = counts,
        tpm = tpm,
        length = length,
        normalized = normalized,
        vst = vst,
        rlog = rlog
    )

    # Metadata -----------------------------------------------------------------
    metadata <- list(
        version = packageVersion,
        level = level,
        caller = caller,
        countsFromAbundance = countsFromAbundance,
        uploadDir = uploadDir,
        sampleDirs = sampleDirs,
        sampleMetadataFile = as.character(sampleMetadataFile),
        projectDir = projectDir,
        template = template,
        runDate = runDate,
        interestingGroups = interestingGroups,
        organism = as.character(organism),
        genomeBuild = as.character(genomeBuild),
        ensemblRelease = as.integer(ensemblRelease),
        rowRangesMetadata = rowRangesMetadata,
        gffFile = as.character(gffFile),
        tx2gene = tx2gene,
        lanes = lanes,
        yaml = yaml,
        dataVersions = dataVersions,
        programVersions = programVersions,
        bcbioLog = bcbioLog,
        bcbioCommandsLog = bcbioCommandsLog,
        allSamples = allSamples,
        call = call
    )

    # Return -------------------------------------------------------------------
    .new.bcbioRNASeq(
        assays = assays,
        rowRanges = rowRanges,
        colData = colData,
        metadata = metadata,
        transgeneNames = transgeneNames,
        spikeNames = spikeNames
    )
}



# Used for bcbio pipeline checks.
.dataHasVariation <- function(dds) {
    !all(rowSums(assay(dds) == assay(dds)[, 1L]) == ncol(dds))
}
